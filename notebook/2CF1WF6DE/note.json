{
  "paragraphs": [
    {
      "title": "SPARK \u0027rdfs\u0027 Reasoning example",
      "text": "import java.io.File\nimport java.net.URI\n\nimport net.sansa_stack.inference.rules.{RDFSLevel, ReasoningProfile}\nimport net.sansa_stack.inference.rules.ReasoningProfile._\nimport net.sansa_stack.inference.spark.data.loader.RDFGraphLoader\nimport net.sansa_stack.inference.spark.data.writer.RDFGraphWriter\nimport net.sansa_stack.inference.spark.forwardchaining.triples.{ForwardRuleReasonerOWLHorst, ForwardRuleReasonerRDFS, TransitiveReasoner}\n\n// load triples from disk\nval input \u003d \"hdfs://namenode:8020/data/rdf.nt\"\nval output \u003d \"hdfs://namenode:8020/data/output/\"\nval argprofile \u003d \"rdfs\"\n\n// check if output exists and remove if necessary\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.conf.Configuration\nval conf \u003d new Configuration()\nval fs \u003d FileSystem.get(new URI(\"hdfs://namenode:8020\"), conf)\nval resultsPath \u003d new org.apache.hadoop.fs.Path(\"/data/output\")\nif(fs.exists(resultsPath))\n  fs.delete(resultsPath, true)\n\nval profile \u003d argprofile match {\n      case \"rdfs\"        \u003d\u003e ReasoningProfile.RDFS\n      case \"rdfs-simple\" \u003d\u003e ReasoningProfile.RDFS_SIMPLE\n      case \"owl-horst\"   \u003d\u003e ReasoningProfile.OWL_HORST\n      case \"transitive\"  \u003d\u003e ReasoningProfile.TRANSITIVE\n\n}\n\n// the degree of parallelism\nval parallelism \u003d 4\n\n// load triples from disk\nval graph \u003d RDFGraphLoader.loadFromDisk(spark, URI.create(input), parallelism)\nprintln(s\"|G|\u003d${graph.size()}\")\n\n// create reasoner\nval reasoner \u003d profile match {\n   case TRANSITIVE \u003d\u003e new TransitiveReasoner(spark.sparkContext, parallelism)\n   case RDFS       \u003d\u003e new ForwardRuleReasonerRDFS(spark.sparkContext, parallelism)\n   case RDFS_SIMPLE \u003d\u003e\n   var r \u003d new ForwardRuleReasonerRDFS(spark.sparkContext, parallelism) //.level.+(RDFSLevel.SIMPLE)\n     r.level \u003d RDFSLevel.SIMPLE\n     r\n   case OWL_HORST \u003d\u003e new ForwardRuleReasonerOWLHorst(spark.sparkContext)\n}\n\n// compute inferred graph\nval inferredGraph \u003d reasoner.apply(graph)\nprintln(s\"|G_inferred|\u003d${inferredGraph.size()}\")\n\n// write triples to disk\n//RDFGraphWriter.writeToDisk(inferredGraph, output)\n\nval O_graph \u003d \"original graph\" + \"\\t\" + graph.size \nval I_Graph \u003d \"\\n inferred graph\" + \"\\t\" + inferredGraph.size\n\nprintln(\"%table graph\\t size\\n \" + O_graph.union(I_Graph))",
      "user": "anonymous",
      "dateUpdated": "Feb 9, 2018 2:32:45 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {
          "1": {
            "graph": {
              "mode": "multiBarChart",
              "height": 300.0,
              "optionOpen": false
            },
            "helium": {}
          }
        },
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\nimport java.io.File\n\nimport java.net.URI\n\nimport net.sansa_stack.inference.rules.{RDFSLevel, ReasoningProfile}\n\nimport net.sansa_stack.inference.rules.ReasoningProfile._\n\nimport net.sansa_stack.inference.spark.data.loader.RDFGraphLoader\n\nimport net.sansa_stack.inference.spark.data.writer.RDFGraphWriter\n\nimport net.sansa_stack.inference.spark.forwardchaining.triples.{ForwardRuleReasonerOWLHorst, ForwardRuleReasonerRDFS, TransitiveReasoner}\n\ninput: String \u003d hdfs://namenode:8020/data/rdf.nt\n\noutput: String \u003d hdfs://namenode:8020/data/output/\n\nargprofile: String \u003d rdfs\n\nimport org.apache.hadoop.fs.FileSystem\n\nimport org.apache.hadoop.conf.Configuration\n\nconf: org.apache.hadoop.conf.Configuration \u003d Configuration: core-default.xml, core-site.xml, mapred-default.xml, mapred-site.xml, yarn-default.xml, yarn-site.xml, hdfs-default.xml, hdfs-site.xml\n\nfs: org.apache.hadoop.fs.FileSystem \u003d DFS[DFSClient[clientName\u003dDFSClient_NONMAPREDUCE_2059290783_30, ugi\u003droot (auth:SIMPLE)]]\n\nresultsPath: org.apache.hadoop.fs.Path \u003d /data/output\n\nres9: AnyVal \u003d ()\n\nprofile: net.sansa_stack.inference.rules.ReasoningProfile.Value \u003d RDFS\n\nparallelism: Int \u003d 4\n\ngraph: net.sansa_stack.inference.spark.data.model.RDFGraph \u003d RDFGraph(MapPartitionsRDD[129] at map at RDFGraphLoader.scala:45)\n|G|\u003d106\n\nreasoner: net.sansa_stack.inference.spark.forwardchaining.triples.TransitiveReasoner \u003d net.sansa_stack.inference.spark.forwardchaining.triples.ForwardRuleReasonerRDFS@d919c80\n\ninferredGraph: net.sansa_stack.inference.spark.data.model.RDFGraph \u003d RDFGraph(MapPartitionsRDD[166] at distinct at ForwardRuleReasonerRDFS.scala:217)\n|G_inferred|\u003d148\n\nO_graph: String \u003d original graph\t106\n\n\n\nI_Graph: String \u003d\n\"\n inferred graph\t148\"\n"
          },
          {
            "type": "TABLE",
            "data": "graph\t size\n original graph\t106\n inferred graph\t148\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1501502646527_985634075",
      "id": "20170731-120406_1649830490",
      "dateCreated": "Jul 31, 2017 12:04:06 PM",
      "dateStarted": "Feb 9, 2018 2:32:45 PM",
      "dateFinished": "Feb 9, 2018 2:32:51 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "Feb 9, 2018 10:22:39 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1501503287502_-938762787",
      "id": "20170731-121447_2118263645",
      "dateCreated": "Jul 31, 2017 12:14:47 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Inference",
  "id": "2CF1WF6DE",
  "angularObjects": {
    "2D7BKGD1V:shared_process": [],
    "2D7H4EN2G:shared_process": [],
    "2D77B7ZGW:shared_process": [],
    "2D6VHZHQ2:shared_process": [],
    "2D77Z6R4F:shared_process": [],
    "2D5MW2J27:shared_process": [],
    "2D7W1W328:shared_process": [],
    "2D5R85FJ6:shared_process": [],
    "2D7N1N3GD:shared_process": [],
    "2D84HKUMR:shared_process": [],
    "2D81Z75XD:shared_process": [],
    "2D7C5CCPT:shared_process": [],
    "2D62Q6PX8:shared_process": [],
    "2D7B6UQMC:shared_process": [],
    "2D6PWZ6A1:shared_process": [],
    "2D7SGRFBB:shared_process": [],
    "2D59VA664:shared_process": [],
    "2D6YHWCHJ:shared_process": [],
    "2D5945ZMD:shared_process": []
  },
  "config": {},
  "info": {}
}